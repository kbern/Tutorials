{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Binary Classification: Voicemails\n",
    "### Similar to the Kaggle's \"Titanic\" problem, we will be building a model that predicts one of two different possible outcomes. We will be using meta-data (variables that describe details about the calls, but without transcripts) and already trained data in order to predict whether or not a call is a voicemail or not.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### As always, we will start by importing the necessary libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd \n",
    "import numpy as np\n",
    "import numpy\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from datetime import *\n",
    "from datetime import datetime\n",
    "from dateutil.relativedelta import *\n",
    "from time import time\n",
    "import boto3\n",
    "from sklearn.feature_selection import SelectKBest, f_classif\n",
    "from pandas.tseries.holiday import USFederalHolidayCalendar as calendar\n",
    "from sklearn.feature_selection import chi2\n",
    "from random import randrange\n",
    "from sklearn import linear_model\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.linear_model import Perceptron\n",
    "from sklearn.linear_model import SGDClassifier\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.svm import SVC, LinearSVC\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.model_selection import cross_val_predict\n",
    "from sklearn.metrics import confusion_matrix\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### We will now access our desired data by pulling out the 'output.csv' file from the data-science-tutorials folder in S3 on AWS. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "bucket = 'data-science-tutorials'\n",
    "key = 'output.csv'\n",
    "\n",
    "s3 = boto3.resource('s3')\n",
    "\n",
    "s3.Bucket(bucket).download_file(key,key)\n",
    "\n",
    "df = pd.read_csv('./output.csv')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### First let's visualize our dataframe:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                CALLID                 date day_of_week  \\\n",
      "0     16050390083911f7  2016-05-03T12:04:43     Tuesday   \n",
      "1     1605092f460485e7  2016-05-09T09:07:42      Monday   \n",
      "2     160509fe3f1cc9c6  2016-05-09T15:56:09      Monday   \n",
      "3     1605107036c49a76  2016-05-10T10:08:37     Tuesday   \n",
      "4     1605047cea3ff9b4  2016-05-04T15:15:31   Wednesday   \n",
      "5     160601f2ebcad14b  2016-06-01T13:59:04   Wednesday   \n",
      "6     16060315848e0390  2016-06-03T10:45:30      Friday   \n",
      "7     160601f300f8b0df  2016-06-01T09:50:38   Wednesday   \n",
      "8     160609f173e2810b  2016-06-09T08:15:36    Thursday   \n",
      "9     160609bf3d7779c4  2016-06-09T16:41:09    Thursday   \n",
      "10    16071476e1540a8d  2016-07-14T15:53:41    Thursday   \n",
      "11    160705b0e6e67685  2016-07-05T11:49:52     Tuesday   \n",
      "12    1607163a321d9bf4  2016-07-16T11:35:00    Saturday   \n",
      "13    1607076b6261523c  2016-07-07T16:01:20    Thursday   \n",
      "14    16071359ec4acd90  2016-07-13T14:19:57   Wednesday   \n",
      "15    160801981d2e1916  2016-08-01T10:20:39      Monday   \n",
      "16    1608265ffa1cc63e  2016-08-26T11:12:14      Friday   \n",
      "17    1608173b5b6ffb0a  2016-08-17T13:43:49   Wednesday   \n",
      "18    16082616d8cdfb0b  2016-08-26T14:43:37      Friday   \n",
      "19    1608246b70acc18d  2016-08-24T09:43:16   Wednesday   \n",
      "20    16092612ecbf22d3  2016-09-26T10:26:08      Monday   \n",
      "21    16090689703bb8dc  2016-09-06T14:25:58     Tuesday   \n",
      "22    16092677b60cd185  2016-09-26T12:42:10      Monday   \n",
      "23    160916c53a89e0c2  2016-09-16T19:52:08      Friday   \n",
      "24    160901bddc1c0f4b  2016-09-01T11:00:45    Thursday   \n",
      "25    1610119a3842cb52  2016-10-11T14:54:45     Tuesday   \n",
      "26    161014a94278a664  2016-10-14T10:50:15      Friday   \n",
      "27    1610116d042ade07  2016-10-11T15:56:21     Tuesday   \n",
      "28    16101203129462dc  2016-10-12T12:39:57   Wednesday   \n",
      "29    161011acf9dc34c0  2016-10-11T17:44:02     Tuesday   \n",
      "...                ...                  ...         ...   \n",
      "4969  160920ec65a5e7fb  2016-09-20T13:56:46     Tuesday   \n",
      "4970  160930cf47f8a96b  2016-09-30T18:31:12      Friday   \n",
      "4971  160909c60cc084c7  2016-09-09T14:40:00      Friday   \n",
      "4972  160818e1894a622a  2016-08-18T08:05:45    Thursday   \n",
      "4973  1608083848f4a179  2016-08-08T13:17:22      Monday   \n",
      "4974  1608088c29e816a8  2016-08-08T15:17:58      Monday   \n",
      "4975  16081748ace1f959  2016-08-17T11:38:43   Wednesday   \n",
      "4976  1608025b1b51b43f  2016-08-02T15:35:32     Tuesday   \n",
      "4977  16081755f2985c32  2016-08-17T10:27:25   Wednesday   \n",
      "4978  160810674250d204  2016-08-10T11:43:25   Wednesday   \n",
      "4979  1608019bc283b822  2016-08-01T14:31:56      Monday   \n",
      "4980  1608315457d83b1a  2016-08-31T09:02:26   Wednesday   \n",
      "4981  1608131fe4988cfa  2016-08-13T21:15:23    Saturday   \n",
      "4982  160930b1e2c69f06  2016-09-30T14:11:32      Friday   \n",
      "4983  16092012a0c1b351  2016-09-20T13:36:25     Tuesday   \n",
      "4984  16093087b83d7d67  2016-09-30T09:24:23      Friday   \n",
      "4985  160920d7a4d9181f  2016-09-20T15:25:17     Tuesday   \n",
      "4986  1608024bdf5caca4  2016-08-02T15:54:36     Tuesday   \n",
      "4987  160805703f308bce  2016-08-05T11:26:12      Friday   \n",
      "4988  1608173e1ab274c2  2016-08-17T12:38:33   Wednesday   \n",
      "4989  160817a0f84a8193  2016-08-17T16:59:41   Wednesday   \n",
      "4990  1608080904665f6a  2016-08-08T16:49:06      Monday   \n",
      "4991  16082420158672d7  2016-08-24T15:26:03   Wednesday   \n",
      "4992  160810d255227a1f  2016-08-10T16:34:21   Wednesday   \n",
      "4993  160816978165b0cf  2016-08-16T13:07:02     Tuesday   \n",
      "4994  160816e0f923a227  2016-08-16T08:48:24     Tuesday   \n",
      "4995  160817a9b6a0ca51  2016-08-17T17:40:42   Wednesday   \n",
      "4996  1608113e75bc9a9a  2016-08-11T11:21:43    Thursday   \n",
      "4997  160805ee889e50ad  2016-08-05T13:32:44      Friday   \n",
      "4998  1608296ebdd338a1  2016-08-29T18:21:29      Monday   \n",
      "\n",
      "      call_duration_seconds  in_detail  out_detail  switches Voice Mail  \n",
      "0                       103   38.68997    55.92999        16         No  \n",
      "1                       123   55.58997    55.78998         5         No  \n",
      "2                       335  130.28990   150.25010       107         No  \n",
      "3                       291  157.11000   168.16990        38         No  \n",
      "4                       361  174.49002   116.25009        31         No  \n",
      "5                        73    9.45001    25.91000         0        Yes  \n",
      "6                       134   76.22999    46.51006        55         No  \n",
      "7                       181   75.38999   106.82998        34         No  \n",
      "8                       156   84.76993    55.12998        16        Yes  \n",
      "9                       121   70.74999    63.94997        15         No  \n",
      "10                      148   36.15000    65.55000        16         No  \n",
      "11                       46   10.39000    14.87000        10         No  \n",
      "12                      272  156.22987   146.54989        64         No  \n",
      "13                      187   84.94998   108.68994        18         No  \n",
      "14                      109   20.41000    55.99000         0        Yes  \n",
      "15                       89   50.60998    54.20997        19         No  \n",
      "16                      250  128.61000    84.04996        31         No  \n",
      "17                       65   45.83000     0.00000         0         No  \n",
      "18                      263   83.13000    70.66998        31         No  \n",
      "19                      380  182.96993   149.55003        18         No  \n",
      "20                      113   63.72998    47.83001        13         No  \n",
      "21                      167   52.05000    86.19002        12        Yes  \n",
      "22                      132   63.03001    61.83001        18         No  \n",
      "23                      492  177.73000   218.92993        60         No  \n",
      "24                      137   74.51004    91.83006        40         No  \n",
      "25                       84   23.60997    35.83000         0        Yes  \n",
      "26                      303  155.49009   119.73012        21         No  \n",
      "27                      286   87.16991   127.73008        38         No  \n",
      "28                       72   25.83001    40.99000        11         No  \n",
      "29                       68   30.33000    22.81000        21         No  \n",
      "...                     ...        ...         ...       ...        ...  \n",
      "4969                     85   40.41001    28.75001         3         No  \n",
      "4970                     75   46.19000    33.90998        11         No  \n",
      "4971                     75   31.37001    32.10999        17         No  \n",
      "4972                    171   45.48994    60.64993         4         No  \n",
      "4973                     67   29.41000    38.41000        20         No  \n",
      "4974                     64   22.73000    12.61000         3         No  \n",
      "4975                    269  118.60996   135.74994        58         No  \n",
      "4976                    197   89.33008    66.48994        15        Yes  \n",
      "4977                    308   85.70999   125.92984        74         No  \n",
      "4978                    145   63.02998    54.53005        19         No  \n",
      "4979                    148   64.10997    73.55001        22         No  \n",
      "4980                    223   75.43001   117.37002        34         No  \n",
      "4981                    178   93.64999    94.37000        20         No  \n",
      "4982                    186   94.84997   102.03001        49         No  \n",
      "4983                    345  213.86998   181.07017        45         No  \n",
      "4984                    325  134.68993   151.81016        70         No  \n",
      "4985                    191  119.99002    67.05002        27         No  \n",
      "4986                    194   64.58994    86.82999        14        Yes  \n",
      "4987                    117   38.20998    57.35000        13         No  \n",
      "4988                    108   62.05004    40.54995        17         No  \n",
      "4989                     81   48.54999    26.21001         1         No  \n",
      "4990                     89   41.33003    38.69001        19         No  \n",
      "4991                    163   69.56998    79.55004        43         No  \n",
      "4992                    164   86.22998    53.80996        33         No  \n",
      "4993                     89   23.13004    23.95000         2        Yes  \n",
      "4994                    237  155.87002   129.18987        95         No  \n",
      "4995                     91   19.08998    54.73000         0         No  \n",
      "4996                    129   47.79001    46.45000        29         No  \n",
      "4997                     83   41.24999    47.27001        13         No  \n",
      "4998                    122   39.14996    61.14999         0        Yes  \n",
      "\n",
      "[4999 rows x 8 columns]\n"
     ]
    }
   ],
   "source": [
    "print(df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Before we can build machine learning models, we must preprocess the data, create new variables, or any other manipulation that may improve our model. Since the *date* feature is written as a date attatched to a time, we will separate the variables from each other and create a new *time* feature. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "#adjust the 'time' column by cutting the first 11 characters off of time\n",
    "df['time'] = df['date'].map(lambda x: str(x)[11:])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### We can create a new feature out of *date* called *holiday*, which gives a boolean value of whether or not it is a national holiday for a specific day. In order to create this however, the *date* feature needs to be in 'datetime' format so the calendar function will work."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "#convert date to datetime\n",
    "df['date'] = pd.to_datetime(df['date'], errors='coerce')\n",
    "\n",
    "#check for holidays \n",
    "dr = pd.date_range(start='2016-05-03', end='2016-08-29')\n",
    "cal = calendar()\n",
    "holidays = cal.holidays(start=dr.min(), end=dr.max())\n",
    "df['holiday'] = df['date'].dt.date.astype('datetime64').isin(holidays)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Here we will transform *date* so that is has only numbers."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "#convert date to int\n",
    "df['date'] = df['date'].dt.strftime('%Y%m%d')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### We will also create a new *hour* variable out of *time* by just taking the first two characters and converting them into an integer. This is useful because it helps to run a large dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "#create new feature 'hour'\n",
    "df['hour'] = df['time'].map(lambda x: str(x)[:2])\n",
    "df['hour'] = df['hour'].astype(int)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### In order to process *day_of_week* in a machine learning model, each day of the week must be mapped to an integer."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "weekday = {'Monday': 0, 'Tuesday': 1, 'Wednesday': 2, 'Thursday': 3, 'Friday': 4, 'Saturday': 5, 'Sunday': 6}\n",
    "df['day_of_week'] = df['day_of_week'].map(weekday)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### We can create another variable out of *day_of_week* that outputs a boolean for whether or not it is a weekend. This could be useful to our model because there may be a correlation between whether or not a call goes to voicemail and whether or not it is the weekend. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "#create feature 'weekend'\n",
    "weekend = [5,6]\n",
    "df['weekend'] = df['day_of_week'].isin(weekend)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Now that we are done creating new variables and adjusting old ones, we can visualize our dataframe. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                CALLID      date  day_of_week  call_duration_seconds  \\\n",
      "0     16050390083911f7  20160503            1                    103   \n",
      "1     1605092f460485e7  20160509            0                    123   \n",
      "2     160509fe3f1cc9c6  20160509            0                    335   \n",
      "3     1605107036c49a76  20160510            1                    291   \n",
      "4     1605047cea3ff9b4  20160504            2                    361   \n",
      "5     160601f2ebcad14b  20160601            2                     73   \n",
      "6     16060315848e0390  20160603            4                    134   \n",
      "7     160601f300f8b0df  20160601            2                    181   \n",
      "8     160609f173e2810b  20160609            3                    156   \n",
      "9     160609bf3d7779c4  20160609            3                    121   \n",
      "10    16071476e1540a8d  20160714            3                    148   \n",
      "11    160705b0e6e67685  20160705            1                     46   \n",
      "12    1607163a321d9bf4  20160716            5                    272   \n",
      "13    1607076b6261523c  20160707            3                    187   \n",
      "14    16071359ec4acd90  20160713            2                    109   \n",
      "15    160801981d2e1916  20160801            0                     89   \n",
      "16    1608265ffa1cc63e  20160826            4                    250   \n",
      "17    1608173b5b6ffb0a  20160817            2                     65   \n",
      "18    16082616d8cdfb0b  20160826            4                    263   \n",
      "19    1608246b70acc18d  20160824            2                    380   \n",
      "20    16092612ecbf22d3  20160926            0                    113   \n",
      "21    16090689703bb8dc  20160906            1                    167   \n",
      "22    16092677b60cd185  20160926            0                    132   \n",
      "23    160916c53a89e0c2  20160916            4                    492   \n",
      "24    160901bddc1c0f4b  20160901            3                    137   \n",
      "25    1610119a3842cb52  20161011            1                     84   \n",
      "26    161014a94278a664  20161014            4                    303   \n",
      "27    1610116d042ade07  20161011            1                    286   \n",
      "28    16101203129462dc  20161012            2                     72   \n",
      "29    161011acf9dc34c0  20161011            1                     68   \n",
      "...                ...       ...          ...                    ...   \n",
      "4969  160920ec65a5e7fb  20160920            1                     85   \n",
      "4970  160930cf47f8a96b  20160930            4                     75   \n",
      "4971  160909c60cc084c7  20160909            4                     75   \n",
      "4972  160818e1894a622a  20160818            3                    171   \n",
      "4973  1608083848f4a179  20160808            0                     67   \n",
      "4974  1608088c29e816a8  20160808            0                     64   \n",
      "4975  16081748ace1f959  20160817            2                    269   \n",
      "4976  1608025b1b51b43f  20160802            1                    197   \n",
      "4977  16081755f2985c32  20160817            2                    308   \n",
      "4978  160810674250d204  20160810            2                    145   \n",
      "4979  1608019bc283b822  20160801            0                    148   \n",
      "4980  1608315457d83b1a  20160831            2                    223   \n",
      "4981  1608131fe4988cfa  20160813            5                    178   \n",
      "4982  160930b1e2c69f06  20160930            4                    186   \n",
      "4983  16092012a0c1b351  20160920            1                    345   \n",
      "4984  16093087b83d7d67  20160930            4                    325   \n",
      "4985  160920d7a4d9181f  20160920            1                    191   \n",
      "4986  1608024bdf5caca4  20160802            1                    194   \n",
      "4987  160805703f308bce  20160805            4                    117   \n",
      "4988  1608173e1ab274c2  20160817            2                    108   \n",
      "4989  160817a0f84a8193  20160817            2                     81   \n",
      "4990  1608080904665f6a  20160808            0                     89   \n",
      "4991  16082420158672d7  20160824            2                    163   \n",
      "4992  160810d255227a1f  20160810            2                    164   \n",
      "4993  160816978165b0cf  20160816            1                     89   \n",
      "4994  160816e0f923a227  20160816            1                    237   \n",
      "4995  160817a9b6a0ca51  20160817            2                     91   \n",
      "4996  1608113e75bc9a9a  20160811            3                    129   \n",
      "4997  160805ee889e50ad  20160805            4                     83   \n",
      "4998  1608296ebdd338a1  20160829            0                    122   \n",
      "\n",
      "      in_detail  out_detail  switches Voice Mail      time  holiday  hour  \\\n",
      "0      38.68997    55.92999        16         No  12:04:43    False    12   \n",
      "1      55.58997    55.78998         5         No  09:07:42    False     9   \n",
      "2     130.28990   150.25010       107         No  15:56:09    False    15   \n",
      "3     157.11000   168.16990        38         No  10:08:37    False    10   \n",
      "4     174.49002   116.25009        31         No  15:15:31    False    15   \n",
      "5       9.45001    25.91000         0        Yes  13:59:04    False    13   \n",
      "6      76.22999    46.51006        55         No  10:45:30    False    10   \n",
      "7      75.38999   106.82998        34         No  09:50:38    False     9   \n",
      "8      84.76993    55.12998        16        Yes  08:15:36    False     8   \n",
      "9      70.74999    63.94997        15         No  16:41:09    False    16   \n",
      "10     36.15000    65.55000        16         No  15:53:41    False    15   \n",
      "11     10.39000    14.87000        10         No  11:49:52    False    11   \n",
      "12    156.22987   146.54989        64         No  11:35:00    False    11   \n",
      "13     84.94998   108.68994        18         No  16:01:20    False    16   \n",
      "14     20.41000    55.99000         0        Yes  14:19:57    False    14   \n",
      "15     50.60998    54.20997        19         No  10:20:39    False    10   \n",
      "16    128.61000    84.04996        31         No  11:12:14    False    11   \n",
      "17     45.83000     0.00000         0         No  13:43:49    False    13   \n",
      "18     83.13000    70.66998        31         No  14:43:37    False    14   \n",
      "19    182.96993   149.55003        18         No  09:43:16    False     9   \n",
      "20     63.72998    47.83001        13         No  10:26:08    False    10   \n",
      "21     52.05000    86.19002        12        Yes  14:25:58    False    14   \n",
      "22     63.03001    61.83001        18         No  12:42:10    False    12   \n",
      "23    177.73000   218.92993        60         No  19:52:08    False    19   \n",
      "24     74.51004    91.83006        40         No  11:00:45    False    11   \n",
      "25     23.60997    35.83000         0        Yes  14:54:45    False    14   \n",
      "26    155.49009   119.73012        21         No  10:50:15    False    10   \n",
      "27     87.16991   127.73008        38         No  15:56:21    False    15   \n",
      "28     25.83001    40.99000        11         No  12:39:57    False    12   \n",
      "29     30.33000    22.81000        21         No  17:44:02    False    17   \n",
      "...         ...         ...       ...        ...       ...      ...   ...   \n",
      "4969   40.41001    28.75001         3         No  13:56:46    False    13   \n",
      "4970   46.19000    33.90998        11         No  18:31:12    False    18   \n",
      "4971   31.37001    32.10999        17         No  14:40:00    False    14   \n",
      "4972   45.48994    60.64993         4         No  08:05:45    False     8   \n",
      "4973   29.41000    38.41000        20         No  13:17:22    False    13   \n",
      "4974   22.73000    12.61000         3         No  15:17:58    False    15   \n",
      "4975  118.60996   135.74994        58         No  11:38:43    False    11   \n",
      "4976   89.33008    66.48994        15        Yes  15:35:32    False    15   \n",
      "4977   85.70999   125.92984        74         No  10:27:25    False    10   \n",
      "4978   63.02998    54.53005        19         No  11:43:25    False    11   \n",
      "4979   64.10997    73.55001        22         No  14:31:56    False    14   \n",
      "4980   75.43001   117.37002        34         No  09:02:26    False     9   \n",
      "4981   93.64999    94.37000        20         No  21:15:23    False    21   \n",
      "4982   94.84997   102.03001        49         No  14:11:32    False    14   \n",
      "4983  213.86998   181.07017        45         No  13:36:25    False    13   \n",
      "4984  134.68993   151.81016        70         No  09:24:23    False     9   \n",
      "4985  119.99002    67.05002        27         No  15:25:17    False    15   \n",
      "4986   64.58994    86.82999        14        Yes  15:54:36    False    15   \n",
      "4987   38.20998    57.35000        13         No  11:26:12    False    11   \n",
      "4988   62.05004    40.54995        17         No  12:38:33    False    12   \n",
      "4989   48.54999    26.21001         1         No  16:59:41    False    16   \n",
      "4990   41.33003    38.69001        19         No  16:49:06    False    16   \n",
      "4991   69.56998    79.55004        43         No  15:26:03    False    15   \n",
      "4992   86.22998    53.80996        33         No  16:34:21    False    16   \n",
      "4993   23.13004    23.95000         2        Yes  13:07:02    False    13   \n",
      "4994  155.87002   129.18987        95         No  08:48:24    False     8   \n",
      "4995   19.08998    54.73000         0         No  17:40:42    False    17   \n",
      "4996   47.79001    46.45000        29         No  11:21:43    False    11   \n",
      "4997   41.24999    47.27001        13         No  13:32:44    False    13   \n",
      "4998   39.14996    61.14999         0        Yes  18:21:29    False    18   \n",
      "\n",
      "      weekend  \n",
      "0       False  \n",
      "1       False  \n",
      "2       False  \n",
      "3       False  \n",
      "4       False  \n",
      "5       False  \n",
      "6       False  \n",
      "7       False  \n",
      "8       False  \n",
      "9       False  \n",
      "10      False  \n",
      "11      False  \n",
      "12       True  \n",
      "13      False  \n",
      "14      False  \n",
      "15      False  \n",
      "16      False  \n",
      "17      False  \n",
      "18      False  \n",
      "19      False  \n",
      "20      False  \n",
      "21      False  \n",
      "22      False  \n",
      "23      False  \n",
      "24      False  \n",
      "25      False  \n",
      "26      False  \n",
      "27      False  \n",
      "28      False  \n",
      "29      False  \n",
      "...       ...  \n",
      "4969    False  \n",
      "4970    False  \n",
      "4971    False  \n",
      "4972    False  \n",
      "4973    False  \n",
      "4974    False  \n",
      "4975    False  \n",
      "4976    False  \n",
      "4977    False  \n",
      "4978    False  \n",
      "4979    False  \n",
      "4980    False  \n",
      "4981     True  \n",
      "4982    False  \n",
      "4983    False  \n",
      "4984    False  \n",
      "4985    False  \n",
      "4986    False  \n",
      "4987    False  \n",
      "4988    False  \n",
      "4989    False  \n",
      "4990    False  \n",
      "4991    False  \n",
      "4992    False  \n",
      "4993    False  \n",
      "4994    False  \n",
      "4995    False  \n",
      "4996    False  \n",
      "4997    False  \n",
      "4998    False  \n",
      "\n",
      "[4999 rows x 12 columns]\n"
     ]
    }
   ],
   "source": [
    "print(df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### It's time to start machine learning!\n",
    "### We are going to start off by using almost all of our predictors as X and the feature that we are predicting, *Voice Mail*, as y. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "predictors = ['date', 'call_duration_seconds', 'hour', 'day_of_week','holiday','weekend','switches']\n",
    "X = df[predictors]\n",
    "y = df['Voice Mail']\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Next we will perform feature selection using SelectKBest. Each result corresponds to a feature in the predictors array and represents how inflencial each feature is at predicting whether or not a call is a voicemail. In this examples, we use 'f_classif', the default model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                    feature names\n",
      "Score                            \n",
      "320.722246               switches\n",
      "274.982391  call_duration_seconds\n",
      "245.292680                weekday\n",
      "134.955448                   hour\n",
      "69.824174             day_of_week\n",
      "0.559400                  holiday\n",
      "0.003179                     date \n",
      "\n"
     ]
    }
   ],
   "source": [
    "\n",
    "\n",
    "# Perform feature selection\n",
    "selector = SelectKBest(f_classif, k=7)\n",
    "fit = selector.fit(X, y)\n",
    "# summarize scores\n",
    "numpy.set_printoptions(precision=3)\n",
    "results = pd.DataFrame({\n",
    "    'feature names': ['date','call_duration_seconds', 'hour', 'day_of_week', \n",
    "              'holiday', 'weekday', 'switches'],\n",
    "    'Score': [fit.scores_[0], fit.scores_[1], fit.scores_[2], fit.scores_[3], fit.scores_[4], fit.scores_[5],\n",
    "              fit.scores_[6]]})\n",
    "result_df = results.sort_values(by='Score', ascending=False)\n",
    "result_df = result_df.set_index('Score')\n",
    "print(result_df, \"\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Here we are doing the same thing as above, except that we are now using a chi squared model.  By analyzing both results, we can conclude that *call_duration_seconds*, *weekday*, and *switches* have larger and more positive influences on the model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                      feature names\n",
      "Score                              \n",
      "30273.063469  call_duration_seconds\n",
      "21197.204312               switches\n",
      "225.533137                  weekday\n",
      "84.364875                      hour\n",
      "83.066879               day_of_week\n",
      "0.558666                    holiday\n",
      "0.001209                       date \n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Perform feature selection\n",
    "selector = SelectKBest(chi2, k=7)\n",
    "fit = selector.fit(X, y)\n",
    "# summarize scores\n",
    "numpy.set_printoptions(precision=3)\n",
    "results = pd.DataFrame({\n",
    "    'feature names': ['date','call_duration_seconds', 'hour', 'day_of_week', \n",
    "              'holiday', 'weekday', 'switches'],\n",
    "    'Score': [fit.scores_[0], fit.scores_[1], fit.scores_[2], fit.scores_[3], fit.scores_[4], fit.scores_[5],\n",
    "              fit.scores_[6]]})\n",
    "result_df = results.sort_values(by='Score', ascending=False)\n",
    "result_df = result_df.set_index('Score')\n",
    "print(result_df, \"\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Since the *date* feature seems to have almost no effect on our model, we will get rid of it and redefine our variables.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "predictors = ['call_duration_seconds', 'hour', 'day_of_week','holiday','weekend','switches']\n",
    "X = df[predictors]\n",
    "y = df['Voice Mail']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### While some features are better than others, we are going to keep all of them. Here, we will use [K-Fold Cross Validation](https://machinelearningmastery.com/k-fold-cross-validation/) so that we can get more accurate scores for each model. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GaussianNB scores: [0.802 0.786 0.784 0.772 0.786 0.794 0.782 0.758 0.621 0.782]\n",
      "Mean: 0.7667142996571987\n",
      "Standard Deviation: 0.049805342176859155 \n",
      "\n",
      "SGD scores: [0.844 0.24  0.776 0.85  0.832 0.794 0.826 0.545 0.864 0.866]\n",
      "Mean: 0.7436381433525734\n",
      "Standard Deviation: 0.19039603346955356 \n",
      "\n",
      "KNN scores: [0.834 0.854 0.856 0.84  0.85  0.86  0.838 0.852 0.85  0.864]\n",
      "Mean: 0.8497753015012058\n",
      "Standard Deviation: 0.009137030870610633 \n",
      "\n",
      "Decision tree scores: [0.828 0.832 0.818 0.82  0.824 0.836 0.82  0.79  0.828 0.822]\n",
      "Mean: 0.8217556398225592\n",
      "Standard Deviation: 0.012056866493128177 \n",
      "\n",
      "Logistic Regression scores: [0.852 0.834 0.834 0.836 0.844 0.846 0.836 0.816 0.85  0.828]\n",
      "Mean: 0.8375612718450874\n",
      "Standard Deviation: 0.010412213656773677 \n",
      "\n",
      "Random Forest Scores: [0.862 0.87  0.868 0.868 0.876 0.896 0.858 0.866 0.882 0.888]\n",
      "Mean: 0.8733805471221885\n",
      "Standard Deviation: 0.011322659683253786\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#K-Fold Cross Validation\n",
    "\n",
    "gaussian = GaussianNB()\n",
    "gaussian_scores = cross_val_score(gaussian, X, y, cv=10, scoring = \"accuracy\")\n",
    "\n",
    "print(\"GaussianNB scores:\", gaussian_scores)\n",
    "print(\"Mean:\", gaussian_scores.mean())\n",
    "print(\"Standard Deviation:\", gaussian_scores.std(), \"\\n\")\n",
    "\n",
    "sgd = linear_model.SGDClassifier(max_iter=5, tol=None)\n",
    "sgd_scores = cross_val_score(sgd, X, y, cv=10, scoring = \"accuracy\")\n",
    "\n",
    "print(\"SGD scores:\", sgd_scores)\n",
    "print(\"Mean:\", sgd_scores.mean())\n",
    "print(\"Standard Deviation:\", sgd_scores.std(), \"\\n\")\n",
    "\n",
    "\n",
    "knn = KNeighborsClassifier(n_neighbors = 3)\n",
    "knn_scores = cross_val_score(knn, X, y, cv=10, scoring = \"accuracy\")\n",
    "\n",
    "print(\"KNN scores:\", knn_scores)\n",
    "print(\"Mean:\", knn_scores.mean())\n",
    "print(\"Standard Deviation:\", knn_scores.std(), \"\\n\")\n",
    "\n",
    "\n",
    "\n",
    "decision_tree = DecisionTreeClassifier()\n",
    "dt_scores = cross_val_score(decision_tree, X, y, cv=10, scoring = \"accuracy\")\n",
    "\n",
    "print(\"Decision tree scores:\", dt_scores)\n",
    "print(\"Mean:\", dt_scores.mean())\n",
    "print(\"Standard Deviation:\", dt_scores.std(), \"\\n\")\n",
    "\n",
    "\n",
    "logreg = LogisticRegression()\n",
    "logreg_scores = cross_val_score(logreg, X, y, cv=10, scoring = \"accuracy\")\n",
    "\n",
    "print(\"Logistic Regression scores:\", logreg_scores)\n",
    "print(\"Mean:\", logreg_scores.mean())\n",
    "print(\"Standard Deviation:\", logreg_scores.std(), \"\\n\")\n",
    "\n",
    "rf = RandomForestClassifier(n_estimators=100)\n",
    "rf_scores = cross_val_score(rf, X, y, cv=10, scoring = \"accuracy\")\n",
    "\n",
    "print(\"Random Forest Scores:\", rf_scores)\n",
    "print(\"Mean:\", rf_scores.mean())\n",
    "print(\"Standard Deviation:\", rf_scores.std())\n",
    "print(\"\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### We can also create a dataframe with the mean scores for each model so we can easily visualize our results. The Random Forest Classifier seems to be the best model, with an accuracy score of around 87%. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                             Model 1\n",
      "Score                               \n",
      "0.873381               Random Forest\n",
      "0.849775                         KNN\n",
      "0.837561         Logistic Regression\n",
      "0.821756               Decision Tree\n",
      "0.766714                 Naive Bayes\n",
      "0.743638  Stochastic Gradient Decent \n",
      "\n"
     ]
    }
   ],
   "source": [
    "results = pd.DataFrame({\n",
    "    'Model 1': ['Naive Bayes','Stochastic Gradient Decent', 'KNN', 'Decision Tree', \n",
    "              'Logistic Regression', 'Random Forest'],\n",
    "    'Score': [gaussian_scores.mean(), sgd_scores.mean(), knn_scores.mean(), dt_scores.mean(), logreg_scores.mean(), \n",
    "             rf_scores.mean()]})\n",
    "result_df = results.sort_values(by='Score', ascending=False)\n",
    "result_df = result_df.set_index('Score')\n",
    "print(result_df, \"\\n\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### A [confusion matrix](https://machinelearningmastery.com/confusion-matrix-machine-learning/) is useful because it gives you insight not only into the errors being made by your classifier but more importantly the types of errors that are being made. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "confusion matrix:\n",
      "[[3600  212]\n",
      " [ 394  793]]\n"
     ]
    }
   ],
   "source": [
    "#confusion matrix on random forest model\n",
    "from sklearn.model_selection import cross_val_predict\n",
    "from sklearn.metrics import confusion_matrix\n",
    "predictions = cross_val_predict(rf, X, y, cv=3)\n",
    "print(\"confusion matrix:\")\n",
    "print(confusion_matrix(y, predictions))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Around 3600 results were correctly classified as not being a voicemail and around 210 results were not correctly classified as not being a voicemail. One the other hand, around 400 results were incorrectly classified as being a voicemail and aroud 790 results were correctly classified as being a voicemail."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
